{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709afd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.ops import box_iou\n",
    "from torchvision import ops\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546dd078",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c9ab22",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e863336",
   "metadata": {},
   "source": [
    "===============================\n",
    "1. Data Loading and Preprocessing\n",
    "==============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a5a082",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"/content/drive/MyDrive/NIH_Chest_Xray/Data_Entry_2017_v2020.csv\"\n",
    "bbox_csv_path = \"/content/drive/MyDrive/NIH_Chest_Xray/BBox_List_2017.csv\"\n",
    "bad_labels_csv = \"/content/drive/MyDrive/NIH_Chest_Xray/cxr14_bad_labels.csv\"\n",
    "image_dir = \"/content/drive/MyDrive/NIH_Chest_Xray/images/good\"\n",
    "\n",
    "# Load datasets\n",
    "df = pd.read_csv(csv_path)\n",
    "bbox_df = pd.read_csv(bbox_csv_path)\n",
    "bad_df = pd.read_csv(bad_labels_csv)\n",
    "\n",
    "# Clean column names in the bounding box dataframe\n",
    "bbox_df.columns = [col.strip() for col in bbox_df.columns]\n",
    "print(\"Bounding box data columns:\", bbox_df.columns)\n",
    "\n",
    "# Filter out bad labels and \"No Finding\"\n",
    "bad_images = bad_df[\"Index\"].tolist()\n",
    "df = df[~df['Image Index'].isin(bad_images)]\n",
    "df = df[~df['Finding Labels'].str.contains('No Finding')]\n",
    "\n",
    "# Build class list\n",
    "all_labels = df['Finding Labels'].str.split('|').explode().unique().tolist()\n",
    "classes = sorted(all_labels)\n",
    "print(f\"Classes: {classes}\")\n",
    "print(f\"Number of classes: {len(classes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0611ea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_ids = df[\"Patient ID\"].unique()\n",
    "train_ids, test_ids = train_test_split(patient_ids, test_size=0.25, random_state=random_seed)\n",
    "val_ids, test_ids = train_test_split(test_ids, test_size=0.65, random_state=random_seed)\n",
    "\n",
    "train_df = df[df[\"Patient ID\"].isin(train_ids)]\n",
    "val_df = df[df[\"Patient ID\"].isin(val_ids)]\n",
    "test_df = df[df[\"Patient ID\"].isin(test_ids)]\n",
    "\n",
    "print(f\"Train set size: {len(train_df)}\")\n",
    "print(f\"Validation set size: {len(val_df)}\")\n",
    "print(f\"Test set size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e56dd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['Finding Labels'].str.split('|').explode().value_counts()\n",
    "plt.figure(figsize=(12, 8))\n",
    "labels.plot(kind='bar')\n",
    "plt.title('Distribution of Labels in the Dataset')\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede03282",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_dict = {}\n",
    "for _, row in bbox_df.iterrows():\n",
    "    img_name = row['Image Index']\n",
    "    label = row['Finding Label']\n",
    "    x, y, w, h = float(row['Bbox [x']), float(row['y']), float(row['w']), float(row['h]'])\n",
    "\n",
    "    if img_name not in bbox_dict:\n",
    "        bbox_dict[img_name] = []\n",
    "\n",
    "    bbox_dict[img_name].append({\n",
    "        'label': label,\n",
    "        'bbox': [x, y, w, h]  # [x, y, width, height]\n",
    "    })\n",
    "\n",
    "print(f\"Number of images with bounding boxes: {len(bbox_dict)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ea8a4a",
   "metadata": {},
   "source": [
    "===============================\n",
    "2. Dataset and DataLoader\n",
    "==============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05ac685",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChestXrayDataset(Dataset):\n",
    "    def __init__(self, dataframe, base_dir, bbox_dict=None, transform=None, mode='both'):\n",
    "        self.dataframe = dataframe\n",
    "        self.base_dir = base_dir\n",
    "        self.bbox_dict = bbox_dict if bbox_dict is not None else {}\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "\n",
    "        self.classes = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema',\n",
    "                'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration',\n",
    "                'Mass', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n",
    "\n",
    "        self.image_locations = {}\n",
    "        self._locate_all_images()\n",
    "\n",
    "    def _locate_all_images(self):\n",
    "        for folder_num in range(1, 13):  # images_001 to images_012\n",
    "            folder_name = f\"images_{folder_num:03d}\"\n",
    "            folder_path = os.path.join(self.base_dir, folder_name, \"images\")\n",
    "\n",
    "            if os.path.exists(folder_path):\n",
    "                for img_name in os.listdir(folder_path):\n",
    "                    if img_name.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                        self.image_locations[img_name] = os.path.join(folder_path, img_name)\n",
    "        print(f\"Found {len(self.image_locations)} images in the directory structure\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        img_name = row['Image Index']\n",
    "\n",
    "        img_path = self.image_locations.get(img_name)\n",
    "        if img_path is None:\n",
    "            rand_row = self.dataframe.sample(1).iloc[0]\n",
    "            img_name = rand_row['Image Index']\n",
    "            img_path = self.image_locations.get(img_name)\n",
    "            if img_path is None:\n",
    "                raise FileNotFoundError(f\"Cannot locate image for {img_name}\")\n",
    "\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image_np = np.array(image)\n",
    "\n",
    "        # classification target\n",
    "        labels_list = row['Finding Labels'].split('|')\n",
    "        cls_target = torch.zeros(len(self.classes), dtype=torch.float32)\n",
    "        for lbl in labels_list:\n",
    "            if lbl in self.classes:\n",
    "                cls_target[self.classes.index(lbl)] = 1.0\n",
    "\n",
    "        # detection targets\n",
    "        bboxes = []  # list of [x_min, y_min, x_max, y_max]\n",
    "        det_labels = []\n",
    "        if img_name in self.bbox_dict:\n",
    "            for obj in self.bbox_dict[img_name]:\n",
    "                lbl = obj['label']\n",
    "                if lbl in self.classes:\n",
    "                    x, y, w, h = obj['bbox']\n",
    "                    x1, y1 = x, y\n",
    "                    x2, y2 = x + w, y + h\n",
    "                    bboxes.append([x1, y1, x2, y2])\n",
    "                    det_labels.append(self.classes.index(lbl))\n",
    "\n",
    "        if self.transform:\n",
    "            transformed = self.transform(\n",
    "                image=image_np,\n",
    "                bboxes=bboxes,\n",
    "                labels=det_labels\n",
    "            )\n",
    "            image = transformed['image']\n",
    "            bboxes = transformed.get('bboxes', [])\n",
    "            det_labels = transformed.get('labels', [])\n",
    "        else:\n",
    "            image = torch.from_numpy(image_np).permute(2, 0, 1).float() / 255.0\n",
    "\n",
    "        if bboxes:\n",
    "            boxes = torch.tensor(bboxes, dtype=torch.float32)\n",
    "            labels = torch.tensor(det_labels, dtype=torch.int64)\n",
    "            det_target = {\n",
    "                'boxes': boxes,\n",
    "                'labels': labels + 1,  # Add 1 as FasterRCNN expects 1-indexed class labels (0 is background)\n",
    "                'image_id': torch.tensor([idx]),\n",
    "                'area': (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0]),\n",
    "                'iscrowd': torch.zeros((len(labels),), dtype=torch.int64),\n",
    "                'has_bbox': True\n",
    "            }\n",
    "        else:\n",
    "            det_target = {\n",
    "                'boxes': torch.zeros((0, 4), dtype=torch.float32),\n",
    "                'labels': torch.zeros((0,), dtype=torch.int64),\n",
    "                'image_id': torch.tensor([idx]),\n",
    "                'area': torch.zeros((0,), dtype=torch.float32),\n",
    "                'iscrowd': torch.zeros((0,), dtype=torch.int64),\n",
    "                'has_bbox': False\n",
    "            }\n",
    "\n",
    "        if self.mode == 'classification':\n",
    "            return image, cls_target\n",
    "        elif self.mode == 'detection':\n",
    "            return image, det_target\n",
    "        else:  # mode == 'both'\n",
    "            return image, cls_target, det_target\n",
    "\n",
    "    def get_image_info(self, idx):\n",
    "        \"\"\"Return image name and path for a given index\"\"\"\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        img_name = row['Image Index']\n",
    "\n",
    "        img_path = self.image_locations.get(img_name)\n",
    "        if img_path is None:\n",
    "            img_path = \"Image not found\"\n",
    "\n",
    "        return {\n",
    "            'image_name': img_name,\n",
    "            'image_path': img_path,\n",
    "            'finding_labels': row['Finding Labels']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad86c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0)),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Rotate(limit=10, p=0.3),\n",
    "    A.ColorJitter(brightness=0.1, contrast=0.1, p=0.5),\n",
    "    A.GaussianBlur(blur_limit=(3, 7), p=0.2),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "], bbox_params=A.BboxParams(\n",
    "    format='pascal_voc',  # [x_min, y_min, x_max, y_max]\n",
    "    label_fields=['labels'],\n",
    "    min_visibility=0.2\n",
    "))\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.CenterCrop(224, 224),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "], bbox_params=A.BboxParams(\n",
    "    format='pascal_voc',\n",
    "    label_fields=['labels']\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcddf550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function for handling variable-sized detection targets\n",
    "    \"\"\"\n",
    "    if len(batch[0]) == 2:  # Mode is either 'classification' or 'detection'\n",
    "        if isinstance(batch[0][1], dict):  # Mode is 'detection'\n",
    "            images = []\n",
    "            targets = []\n",
    "            for img, t in batch:\n",
    "                images.append(img)\n",
    "                targets.append(t)\n",
    "            return torch.stack(images, 0), targets\n",
    "        else:  # Mode is 'classification'\n",
    "            return torch.utils.data.dataloader.default_collate(batch)\n",
    "    else:  # Mode is 'both'\n",
    "        images = []\n",
    "        cls_targets = []\n",
    "        det_targets = []\n",
    "        for img, cls_t, det_t in batch:\n",
    "            images.append(img)\n",
    "            cls_targets.append(cls_t)\n",
    "            det_targets.append(det_t)\n",
    "        return torch.stack(images, 0), torch.stack(cls_targets, 0), det_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a383c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ChestXrayDataset(train_df, image_dir, bbox_dict, train_transform, mode='both')\n",
    "val_dataset = ChestXrayDataset(val_df, image_dir, bbox_dict, val_transform, mode='both')\n",
    "test_dataset = ChestXrayDataset(test_df, image_dir, bbox_dict, val_transform, mode='both')\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b93952",
   "metadata": {},
   "source": [
    "# ===============================\n",
    "# 3. Model Architecture\n",
    "# ==============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d142b802",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self, num_classes=14, pretrained=True):\n",
    "        super(MultiTaskModel, self).__init__()\n",
    "        # Load a pretrained DenseNet121 as the shared backbone\n",
    "        self.shared_backbone = models.densenet121(pretrained=pretrained).features\n",
    "        \n",
    "        # Classification head\n",
    "        self.cls_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Set up the detection model (Faster R-CNN) with the same backbone\n",
    "        # We need to extract intermediate features for the detector\n",
    "        self.detection_backbone = self.create_detection_backbone()\n",
    "        \n",
    "        # RPN needs to know the output channels of the backbone\n",
    "        backbone_out_channels = 1024\n",
    "        \n",
    "        # Anchor generator for RPN\n",
    "        anchor_generator = AnchorGenerator(\n",
    "            sizes=((32, 64, 128, 256),),\n",
    "            aspect_ratios=((0.5, 1.0, 2.0),)\n",
    "        )\n",
    "        \n",
    "        # Define the RoI crop size\n",
    "        roi_pooler = torch.nn.modules.pooling.AdaptiveAvgPool2d((7, 7))\n",
    "        \n",
    "        # Create Faster R-CNN detector using our backbone\n",
    "        self.detector = FasterRCNN(\n",
    "            self.detection_backbone,\n",
    "            num_classes=num_classes + 1,  # +1 for background class\n",
    "            rpn_anchor_generator=anchor_generator,\n",
    "            box_roi_pool=roi_pooler,\n",
    "            min_size=224,\n",
    "            max_size=224,\n",
    "            box_score_thresh=0.05,\n",
    "            box_nms_thresh=0.5\n",
    "        )\n",
    "        \n",
    "        # Freeze the shared backbone parameters for the detector\n",
    "        for param in self.shared_backbone.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def create_detection_backbone(self):\n",
    "        # Define a custom backbone that uses the shared features\n",
    "        class CustomBackbone(nn.Module):\n",
    "            def __init__(self, shared_features):\n",
    "                super(CustomBackbone, self).__init__()\n",
    "                self.shared_features = shared_features\n",
    "                \n",
    "            def forward(self, x):\n",
    "                features = self.shared_features(x)\n",
    "                return {'0': features}  # Return feature map as a dict as expected by FasterRCNN\n",
    "        \n",
    "        return CustomBackbone(self.shared_backbone)\n",
    "    \n",
    "    def forward(self, images, targets=None, mode='both'):\n",
    "        if mode == 'classification' or mode == 'both':\n",
    "            # Classification forward pass\n",
    "            features = self.shared_backbone(images)\n",
    "            pooled = self.cls_pool(features)\n",
    "            cls_output = self.classifier(pooled)\n",
    "            \n",
    "            if mode == 'classification':\n",
    "                return cls_output\n",
    "        \n",
    "        if mode == 'detection' or mode == 'both':\n",
    "            # Detection forward pass\n",
    "            if self.training and targets is not None:\n",
    "                # During training, we need to compute losses\n",
    "                det_losses = self.detector(images, targets)\n",
    "                \n",
    "                if mode == 'detection':\n",
    "                    return det_losses\n",
    "                \n",
    "                # For 'both' mode, we return both outputs\n",
    "                return cls_output, det_losses\n",
    "            else:\n",
    "                # During evaluation/inference\n",
    "                det_output = self.detector(images)\n",
    "                \n",
    "                if mode == 'detection':\n",
    "                    return det_output\n",
    "                \n",
    "                # For 'both' mode\n",
    "                return cls_output, det_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec8b68d",
   "metadata": {},
   "source": [
    "# ===============================\n",
    "# 4. Training Configuration\n",
    "# ==============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115d9c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiTaskModel(num_classes=len(classes), pretrained=True).to(device)\n",
    "\n",
    "cls_criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Training constants\n",
    "num_epochs = 30\n",
    "log_interval = 50\n",
    "writer = SummaryWriter('runs/multitask_chest_xray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a509cf3d",
   "metadata": {},
   "source": [
    "# ===============================\n",
    "# 5. Training and Validation Functions\n",
    "# ==============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf03ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, epoch, device):\n",
    "    model.train()\n",
    "    cls_losses = []\n",
    "    rpn_losses = []\n",
    "    roi_losses = []\n",
    "    total_losses = []\n",
    "\n",
    "    batch_count = len(train_loader)\n",
    "    start_time = time.time()\n",
    "\n",
    "    for batch_idx, (images, cls_targets, det_targets) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        cls_targets = cls_targets.to(device)\n",
    "\n",
    "        # Filter out images without bounding boxes for detection training\n",
    "        valid_det_targets = []\n",
    "        valid_det_idxs = []\n",
    "\n",
    "        for i, target in enumerate(det_targets):\n",
    "            if target['has_bbox']:\n",
    "                target = {k: v.to(device) if isinstance(v, torch.Tensor) else v\n",
    "                         for k, v in target.items()}\n",
    "                valid_det_targets.append(target)\n",
    "                valid_det_idxs.append(i)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # If we have valid detection targets\n",
    "        if valid_det_targets:\n",
    "            valid_images = images[valid_det_idxs]\n",
    "            valid_cls_targets = cls_targets[valid_det_idxs]\n",
    "\n",
    "            # Forward pass for images with bounding boxes\n",
    "            cls_output, det_losses = model(valid_images, valid_det_targets, mode='both')\n",
    "\n",
    "            # Calculate classification loss\n",
    "            cls_loss = cls_criterion(cls_output, valid_cls_targets)\n",
    "\n",
    "            # Extract detection losses\n",
    "            rpn_loss = det_losses['loss_objectness'] + det_losses['loss_rpn_box_reg']\n",
    "            roi_loss = det_losses['loss_classifier'] + det_losses['loss_box_reg']\n",
    "\n",
    "            # Total loss\n",
    "            total_loss = cls_loss + rpn_loss + roi_loss\n",
    "\n",
    "            # Backpropagation\n",
    "            total_loss.backward()\n",
    "\n",
    "            # Log losses\n",
    "            cls_losses.append(cls_loss.item())\n",
    "            rpn_losses.append(rpn_loss.item())\n",
    "            roi_losses.append(roi_loss.item())\n",
    "            total_losses.append(total_loss.item())\n",
    "\n",
    "        # Handle images without bounding boxes (classification only)\n",
    "        non_det_idxs = [i for i in range(len(images)) if i not in valid_det_idxs]\n",
    "        if non_det_idxs:\n",
    "            non_det_images = images[non_det_idxs]\n",
    "            non_det_cls_targets = cls_targets[non_det_idxs]\n",
    "\n",
    "            # Forward pass for classification only\n",
    "            cls_output = model(non_det_images, mode='classification')\n",
    "\n",
    "            # Calculate classification loss\n",
    "            cls_loss = cls_criterion(cls_output, non_det_cls_targets)\n",
    "\n",
    "            # Backpropagation\n",
    "            cls_loss.backward()\n",
    "\n",
    "            # Log classification loss\n",
    "            cls_losses.append(cls_loss.item())\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Log progress\n",
    "        if (batch_idx + 1) % log_interval == 0 or (batch_idx + 1) == batch_count:\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f'Epoch {epoch+1}/{num_epochs} [{batch_idx+1}/{batch_count} ({100. * (batch_idx+1) / batch_count:.0f}%)]'\n",
    "                  f' - Time: {elapsed:.1f}s - Cls Loss: {np.mean(cls_losses):.4f}' +\n",
    "                  (f' - RPN Loss: {np.mean(rpn_losses):.4f} - ROI Loss: {np.mean(roi_losses):.4f}'\n",
    "                   if rpn_losses else ''))\n",
    "\n",
    "            # Log to TensorBoard\n",
    "            global_step = epoch * batch_count + batch_idx\n",
    "            writer.add_scalar('train/classification_loss', np.mean(cls_losses), global_step)\n",
    "            if rpn_losses:\n",
    "                writer.add_scalar('train/rpn_loss', np.mean(rpn_losses), global_step)\n",
    "                writer.add_scalar('train/roi_loss', np.mean(roi_losses), global_step)\n",
    "                writer.add_scalar('train/total_loss', np.mean(total_losses), global_step)\n",
    "\n",
    "    # Return average losses for the epoch\n",
    "    avg_cls_loss = np.mean(cls_losses)\n",
    "    avg_rpn_loss = np.mean(rpn_losses) if rpn_losses else 0\n",
    "    avg_roi_loss = np.mean(roi_losses) if roi_losses else 0\n",
    "    avg_total_loss = np.mean(total_losses) if total_losses else avg_cls_loss\n",
    "\n",
    "    return {\n",
    "        'classification_loss': avg_cls_loss,\n",
    "        'rpn_loss': avg_rpn_loss,\n",
    "        'roi_loss': avg_roi_loss,\n",
    "        'total_loss': avg_total_loss\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fe66f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, device, epoch=None, classes=None):\n",
    "    model.eval()\n",
    "    cls_losses = []\n",
    "    all_cls_targets = []\n",
    "    all_cls_preds = []\n",
    "\n",
    "    # For detection evaluation\n",
    "    all_det_targets = []\n",
    "    all_det_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, cls_targets, det_targets in val_loader:\n",
    "            images = images.to(device)\n",
    "            cls_targets = cls_targets.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            cls_output, det_output = model(images, mode='both')\n",
    "\n",
    "            # Classification loss\n",
    "            cls_loss = cls_criterion(cls_output, cls_targets)\n",
    "            cls_losses.append(cls_loss.item())\n",
    "\n",
    "            # Store predictions and targets for metrics calculation\n",
    "            all_cls_targets.append(cls_targets.cpu().numpy())\n",
    "            all_cls_preds.append(torch.sigmoid(cls_output).cpu().numpy())\n",
    "\n",
    "            # Store detection predictions and targets\n",
    "            for i, (target, pred) in enumerate(zip(det_targets, det_output)):\n",
    "                if target['has_bbox']:\n",
    "                    # Convert to numpy for evaluation\n",
    "                    gt_boxes = target['boxes'].cpu().numpy()\n",
    "                    gt_labels = target['labels'].cpu().numpy()\n",
    "\n",
    "                    pred_boxes = pred['boxes'].cpu().numpy()\n",
    "                    pred_scores = pred['scores'].cpu().numpy()\n",
    "                    pred_labels = pred['labels'].cpu().numpy()\n",
    "\n",
    "                    # Store for evaluation\n",
    "                    all_det_targets.append((gt_boxes, gt_labels))\n",
    "                    all_det_preds.append((pred_boxes, pred_scores, pred_labels))\n",
    "\n",
    "    # Calculate classification metrics\n",
    "    all_cls_targets = np.vstack(all_cls_targets)\n",
    "    all_cls_preds = np.vstack(all_cls_preds)\n",
    "\n",
    "    # AUC per class\n",
    "    aucs = []\n",
    "    for i in range(all_cls_targets.shape[1]):\n",
    "        if np.sum(all_cls_targets[:, i]) > 0:  # Only calculate AUC if positive samples exist\n",
    "            auc = roc_auc_score(all_cls_targets[:, i], all_cls_preds[:, i])\n",
    "            aucs.append(auc)\n",
    "        else:\n",
    "            aucs.append(float('nan'))\n",
    "\n",
    "    mean_auc = np.nanmean(aucs)\n",
    "\n",
    "    # Calculate AP per class\n",
    "    aps = []\n",
    "    for i in range(all_cls_targets.shape[1]):\n",
    "        if np.sum(all_cls_targets[:, i]) > 0:  # Only calculate AP if positive samples exist\n",
    "            ap = average_precision_score(all_cls_targets[:, i], all_cls_preds[:, i])\n",
    "            aps.append(ap)\n",
    "        else:\n",
    "            aps.append(float('nan'))\n",
    "\n",
    "    mean_ap_cls = np.nanmean(aps)\n",
    "\n",
    "    # Detection metrics - Calculate mAP\n",
    "    detection_aps = calculate_detection_map(all_det_targets, all_det_preds)\n",
    "    mean_ap_det = np.nanmean(list(detection_aps.values()))\n",
    "\n",
    "    # Log to TensorBoard if epoch is provided\n",
    "    if epoch is not None:\n",
    "        writer.add_scalar('val/classification_loss', np.mean(cls_losses), epoch)\n",
    "        writer.add_scalar('val/mean_auc', mean_auc, epoch)\n",
    "        writer.add_scalar('val/mean_ap_cls', mean_ap_cls, epoch)\n",
    "        writer.add_scalar('val/mean_ap_det', mean_ap_det, epoch)\n",
    "\n",
    "        # Log AUC and AP per class\n",
    "        if classes:\n",
    "            for i, class_name in enumerate(classes):\n",
    "                writer.add_scalar(f'val/auc/{class_name}', aucs[i], epoch)\n",
    "                writer.add_scalar(f'val/ap_cls/{class_name}', aps[i], epoch)\n",
    "                if i+1 in detection_aps:  # +1 because detection labels are 1-indexed\n",
    "                    writer.add_scalar(f'val/ap_det/{class_name}', detection_aps[i+1], epoch)\n",
    "\n",
    "    # Return metrics\n",
    "    metrics = {\n",
    "        'classification_loss': np.mean(cls_losses),\n",
    "        'mean_auc': mean_auc,\n",
    "        'mean_ap_cls': mean_ap_cls,\n",
    "        'mean_ap_det': mean_ap_det,\n",
    "        'aucs': aucs,\n",
    "        'aps_cls': aps,\n",
    "        'aps_det': detection_aps\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542496a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_detection_map(all_targets, all_preds, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Calculate mAP for detection (PASCAL VOC format)\n",
    "    \"\"\"\n",
    "    # Dictionary to store all detections per class\n",
    "    all_detections = {}\n",
    "    # Dictionary to store all ground truths per class\n",
    "    all_ground_truths = {}\n",
    "\n",
    "    # Initialize dictionaries\n",
    "    for i in range(1, 15):  # 1-14 classes (0 is background)\n",
    "        all_detections[i] = []\n",
    "        all_ground_truths[i] = []\n",
    "\n",
    "    # Process all predictions and targets\n",
    "    for (gt_boxes, gt_labels), (pred_boxes, pred_scores, pred_labels) in zip(all_targets, all_preds):\n",
    "        # Add ground truths\n",
    "        for box, label in zip(gt_boxes, gt_labels):\n",
    "            all_ground_truths[label].append(box)\n",
    "\n",
    "        # Add detections\n",
    "        for box, score, label in zip(pred_boxes, pred_scores, pred_labels):\n",
    "            all_detections[label].append((box, score))\n",
    "\n",
    "    # Calculate AP per class\n",
    "    aps = {}\n",
    "    for cls_id in range(1, 15):\n",
    "        if not all_ground_truths[cls_id]:\n",
    "            continue\n",
    "\n",
    "        # Get detections for this class\n",
    "        dets = all_detections[cls_id]\n",
    "        if not dets:\n",
    "            aps[cls_id] = 0.0\n",
    "            continue\n",
    "\n",
    "        # Sort detections by score\n",
    "        dets.sort(key=lambda x: x[1], reverse=True)\n",
    "        boxes = np.array([d[0] for d in dets])\n",
    "        scores = np.array([d[1] for d in dets])\n",
    "\n",
    "        # Get ground truths for this class\n",
    "        gt_boxes = np.array(all_ground_truths[cls_id])\n",
    "\n",
    "        if len(gt_boxes) == 0:\n",
    "            aps[cls_id] = 0.0\n",
    "            continue\n",
    "\n",
    "        # Calculate precision and recall\n",
    "        tp = np.zeros(len(boxes))\n",
    "        fp = np.zeros(len(boxes))\n",
    "        used_gt = np.zeros(len(gt_boxes))\n",
    "\n",
    "        for i, box in enumerate(boxes):\n",
    "            # Find best matching ground truth\n",
    "            if len(gt_boxes) == 0:\n",
    "                fp[i] = 1\n",
    "                continue\n",
    "\n",
    "            # Calculate IoU with all ground truths\n",
    "            ious = []\n",
    "            for gt_box in gt_boxes:\n",
    "                # Convert to tensors for box_iou\n",
    "                box_tensor = torch.tensor([box], dtype=torch.float32)\n",
    "                gt_box_tensor = torch.tensor([gt_box], dtype=torch.float32)\n",
    "                iou = box_iou(box_tensor, gt_box_tensor).item()\n",
    "                ious.append(iou)\n",
    "\n",
    "            # Find best matching ground truth\n",
    "            max_iou_idx = np.argmax(ious)\n",
    "            max_iou = ious[max_iou_idx]\n",
    "\n",
    "            if max_iou >= iou_threshold and not used_gt[max_iou_idx]:\n",
    "                tp[i] = 1\n",
    "                used_gt[max_iou_idx] = 1\n",
    "            else:\n",
    "                fp[i] = 1\n",
    "\n",
    "        # Compute precision and recall\n",
    "        tp_cum = np.cumsum(tp)\n",
    "        fp_cum = np.cumsum(fp)\n",
    "        rec = tp_cum / len(gt_boxes)\n",
    "        prec = tp_cum / (tp_cum + fp_cum)\n",
    "\n",
    "        # Compute AP using 11-point interpolation\n",
    "        ap = 0\n",
    "        for t in np.arange(0, 1.1, 0.1):\n",
    "            if np.sum(rec >= t) == 0:\n",
    "                p = 0\n",
    "            else:\n",
    "                p = np.max(prec[rec >= t])\n",
    "            ap += p / 11\n",
    "\n",
    "        aps[cls_id] = ap\n",
    "\n",
    "    return aps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97d1e43",
   "metadata": {},
   "source": [
    "# ===============================\n",
    "# 6. Training Loop\n",
    "# ==============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dcbdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer, lr_scheduler, num_epochs, device, classes):\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_path = 'best_model.pth'\n",
    "\n",
    "    # Training and validation metrics history\n",
    "    history = {\n",
    "        'train_cls_loss': [],\n",
    "        'train_total_loss': [],\n",
    "        'val_cls_loss': [],\n",
    "        'val_mean_auc': [],\n",
    "        'val_mean_ap_cls': [],\n",
    "        'val_mean_ap_det': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 40)\n",
    "\n",
    "        # Train for one epoch\n",
    "        train_losses = train_epoch(model, train_loader, optimizer, epoch, device)\n",
    "\n",
    "        # Validate\n",
    "        val_metrics = validate(model, val_loader, device, epoch, classes)\n",
    "\n",
    "        # Update learning rate\n",
    "        lr_scheduler.step(val_metrics['classification_loss'])\n",
    "\n",
    "        # Save metrics to history\n",
    "        history['train_cls_loss'].append(train_losses['classification_loss'])\n",
    "        history['train_total_loss'].append(train_losses['total_loss'])\n",
    "        history['val_cls_loss'].append(val_metrics['classification_loss'])\n",
    "        history['val_mean_auc'].append(val_metrics['mean_auc'])\n",
    "        history['val_mean_ap_cls'].append(val_metrics['mean_ap_cls'])\n",
    "        history['val_mean_ap_det'].append(val_metrics['mean_ap_det'])\n",
    "\n",
    "        # Print validation metrics\n",
    "        print(f\"Validation - Cls Loss: {val_metrics['classification_loss']:.4f}, \" +\n",
    "              f\"Mean AUC: {val_metrics['mean_auc']:.4f}, \" +\n",
    "              f\"Cls mAP: {val_metrics['mean_ap_cls']:.4f}, \" +\n",
    "              f\"Det mAP: {val_metrics['mean_ap_det']:.4f}\")\n",
    "\n",
    "        # Save the best model\n",
    "        if val_metrics['classification_loss'] < best_val_loss:\n",
    "            best_val_loss = val_metrics['classification_loss']\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_metrics': val_metrics,\n",
    "            }, best_model_path)\n",
    "            print(f\"Saved best model at epoch {epoch+1}\")\n",
    "\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683499e1",
   "metadata": {},
   "source": [
    "# ===============================\n",
    "# 7. Model Training\n",
    "# ==============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e8ab25",
   "metadata": {},
   "outputs": [],
   "source": [
    "history, trained_model = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    num_epochs=15,\n",
    "    device=device,\n",
    "    classes=classes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1aa4a1d",
   "metadata": {},
   "source": [
    "# ===============================\n",
    "# 8. Results Visualization\n",
    "# ==============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9b5c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_curves(history):\n",
    "    \"\"\"\n",
    "    Plot training and validation curves\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "    # Plot classification loss\n",
    "    axs[0, 0].plot(history['train_cls_loss'], label='Train')\n",
    "    axs[0, 0].plot(history['val_cls_loss'], label='Validation')\n",
    "    axs[0, 0].set_title('Classification Loss')\n",
    "    axs[0, 0].set_xlabel('Epoch')\n",
    "    axs[0, 0].set_ylabel('Loss')\n",
    "    axs[0, 0].legend()\n",
    "\n",
    "    # Plot total loss\n",
    "    axs[0, 1].plot(history['train_total_loss'], label='Train Total Loss')\n",
    "    axs[0, 1].set_title('Total Loss (Classification + Detection)')\n",
    "    axs[0, 1].set_xlabel('Epoch')\n",
    "    axs[0, 1].set_ylabel('Loss')\n",
    "\n",
    "    # Plot AUC\n",
    "    axs[1, 0].plot(history['val_mean_auc'], label='Mean AUC')\n",
    "    axs[1, 0].set_title('Validation Mean AUC')\n",
    "    axs[1, 0].set_xlabel('Epoch')\n",
    "    axs[1, 0].set_ylabel('AUC')\n",
    "\n",
    "    # Plot mAP\n",
    "    axs[1, 1].plot(history['val_mean_ap_cls'], label='Classification mAP')\n",
    "    axs[1, 1].plot(history['val_mean_ap_det'], label='Detection mAP')\n",
    "    axs[1, 1].set_title('Validation Mean Average Precision')\n",
    "    axs[1, 1].set_xlabel('Epoch')\n",
    "    axs[1, 1].set_ylabel('mAP')\n",
    "    axs[1, 1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_curves.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e361d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, dataset, idx, device, classes):\n",
    "    \"\"\"\n",
    "    Visualize image with ground truth and predicted bounding boxes\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Get image info\n",
    "    img_info = dataset.get_image_info(idx)\n",
    "    print(f\"Image: {img_info['image_name']}\")\n",
    "    print(f\"Labels: {img_info['finding_labels']}\")\n",
    "\n",
    "    # Get sample\n",
    "    image, cls_target, det_target = dataset[idx]\n",
    "\n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        input_tensor = image.unsqueeze(0).to(device)\n",
    "        cls_output, det_output = model(input_tensor, mode='both')\n",
    "        cls_probs = torch.sigmoid(cls_output).cpu().numpy()[0]\n",
    "        det_output = det_output[0]\n",
    "\n",
    "    # Get original image for display\n",
    "    img_path = img_info['image_path']\n",
    "    orig_img = np.array(Image.open(img_path).convert('RGB'))\n",
    "\n",
    "    # Create figure\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "    # Plot original image with ground truth boxes\n",
    "    axs[0].imshow(orig_img)\n",
    "    axs[0].set_title('Ground Truth')\n",
    "\n",
    "    if det_target['has_bbox']:\n",
    "        boxes = det_target['boxes'].cpu().numpy()\n",
    "        labels = det_target['labels'].cpu().numpy()\n",
    "\n",
    "        for box, label in zip(boxes, labels):\n",
    "            x1, y1, x2, y2 = box\n",
    "            rect = plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
    "                               fill=False, edgecolor='green', linewidth=2)\n",
    "            axs[0].add_patch(rect)\n",
    "            axs[0].text(x1, y1-10, classes[label-1],\n",
    "                      color='green', fontsize=12,\n",
    "                      bbox=dict(facecolor='white', alpha=0.7))\n",
    "\n",
    "    # Plot original image with predicted boxes\n",
    "    axs[1].imshow(orig_img)\n",
    "    axs[1].set_title('Predictions')\n",
    "\n",
    "    # Plot predictions\n",
    "    boxes = det_output['boxes'].cpu().numpy()\n",
    "    scores = det_output['scores'].cpu().numpy()\n",
    "    labels = det_output['labels'].cpu().numpy()\n",
    "\n",
    "    for box, score, label in zip(boxes, scores, labels):\n",
    "        if score > 0.1:  # Only show confident predictions\n",
    "            x1, y1, x2, y2 = box\n",
    "            rect = plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
    "                               fill=False, edgecolor='red', linewidth=2)\n",
    "            axs[1].add_patch(rect)\n",
    "            axs[1].text(x1, y1-10, f\"{classes[label-1]}: {score:.2f}\",\n",
    "                      color='red', fontsize=12,\n",
    "                      bbox=dict(facecolor='white', alpha=0.7))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'prediction_{idx}.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Print classification results\n",
    "    print(\"\\nClassification Results:\")\n",
    "    results = []\n",
    "    for i, (cls_name, target, prob) in enumerate(zip(classes, cls_target, cls_probs)):\n",
    "        results.append((cls_name, float(target), float(prob)))\n",
    "\n",
    "    # Sort by probability\n",
    "    results.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    for cls_name, target, prob in results:\n",
    "        print(f\"{cls_name}: GT={target:.0f}, Pred={prob:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c34aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device, classes):\n",
    "    \"\"\"\n",
    "    Evaluate model on test set and print detailed metrics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    metrics = validate(model, test_loader, device, classes=classes)\n",
    "\n",
    "    print(\"\\n===== Test Set Evaluation =====\")\n",
    "    print(f\"Classification Loss: {metrics['classification_loss']:.4f}\")\n",
    "    print(f\"Mean AUC: {metrics['mean_auc']:.4f}\")\n",
    "    print(f\"Classification mAP: {metrics['mean_ap_cls']:.4f}\")\n",
    "    print(f\"Detection mAP: {metrics['mean_ap_det']:.4f}\")\n",
    "\n",
    "    # Per-class metrics\n",
    "    print(\"\\nPer-Class Metrics:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Class':20} {'AUC':10} {'Cls AP':10} {'Det AP':10}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    for i, cls_name in enumerate(classes):\n",
    "        auc = metrics['aucs'][i]\n",
    "        ap_cls = metrics['aps_cls'][i]\n",
    "        ap_det = metrics['aps_det'].get(i+1, float('nan'))  # +1 because detection labels are 1-indexed\n",
    "\n",
    "        print(f\"{cls_name:20} {auc:.4f}     {ap_cls:.4f}     {ap_det:.4f}\")\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88e266b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_curves(history)\n",
    "\n",
    "# Visualize predictions for a few samples\n",
    "for idx in [5, 20, 50]:  # Choose some sample indices\n",
    "    visualize_predictions(model, test_dataset, idx, device, classes)\n",
    "\n",
    "test_metrics = evaluate_model(model, test_loader, device, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218c945b",
   "metadata": {},
   "source": [
    "# ===============================\n",
    "# 9. Save Final Model and Results\n",
    "# ==============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cb826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'classes': classes,\n",
    "    'test_metrics': test_metrics,\n",
    "}, 'final_multitask_model.pth')\n",
    "\n",
    "print(\"\\nModel saved to 'final_multitask_model.pth'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
